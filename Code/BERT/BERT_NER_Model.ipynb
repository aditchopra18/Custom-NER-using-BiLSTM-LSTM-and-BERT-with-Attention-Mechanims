{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Relevant Libraries\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing the relevant files\n",
    "train_file = '../../Data/NCBItrainset_corpus.txt'\n",
    "dev_file = '../../Data/NCBIdevelopset_corpus.txt'\n",
    "test_file = '../../Data/NCBItestset_corpus.txt'\n",
    "model_name = '../../Models/BERT_NER_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset file\n",
    "def read_dataset(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    return lines\n",
    "\n",
    "def parse_dataset(lines):\n",
    "    paragraphs = []\n",
    "    paragraph = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            paragraph.append(line)\n",
    "        else:\n",
    "            if paragraph:\n",
    "                paragraphs.append(paragraph)\n",
    "                paragraph = []\n",
    "\n",
    "    if paragraph:\n",
    "        paragraphs.append(paragraph)\n",
    "\n",
    "    return paragraphs\n",
    "\n",
    "def parse_paragraph(paragraph):\n",
    "    sentences = []\n",
    "    annotations = []\n",
    "    sentence = []\n",
    "\n",
    "    for line in paragraph:\n",
    "        if re.match(r'^\\d+\\|\\w\\|', line):\n",
    "            sentence.extend(line.split('|')[2].split())\n",
    "\n",
    "        elif re.match(r'^\\d+\\t\\d+\\t\\d+\\t', line):\n",
    "            start, end = int(line.split(\"\\t\")[1]), int(line.split(\"\\t\")[2])\n",
    "            annotations.append((start, end, line.split(\"\\t\")[3], line.split(\"\\t\")[4]))\n",
    "\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "    return sentences, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Labelling\n",
    "def tag_annotations(sentences, annotations):\n",
    "    tagged_sentences = []\n",
    "    char_count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tags = ['O'] * len(sentence)    # Initialize all tags at \"O\"\n",
    "        word_starts = []\n",
    "        word_ends = []\n",
    "        char_pos = 0\n",
    "\n",
    "        for word in sentence:\n",
    "            word_starts.append(char_pos)\n",
    "            char_pos += len(word)\n",
    "            word_ends.append(char_pos)\n",
    "            char_pos += 1               # WhiteSpace Character\n",
    "\n",
    "        '''\n",
    "        Based on the character limits, the annotations are assigned\n",
    "        A custom IO tagging scheme is used\n",
    "        Labels are assigned on the basis of disease label in annotations\n",
    "        '''\n",
    "\n",
    "        for start, end, disease_info, label in annotations:\n",
    "            for i, (word_start, word_end) in enumerate(zip(word_starts, word_ends)):\n",
    "                if word_start >= start and word_end <= end:\n",
    "                    tags[i] = 'I-' + label\n",
    "                elif word_start < start < word_end or word_start < end < word_end:\n",
    "                    tags[i] = 'I-' + label\n",
    "\n",
    "        tagged_sentences.append((sentence, tags))\n",
    "\n",
    "    return tagged_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the dataset file\n",
    "lines = read_dataset(train_file)\n",
    "paragraphs = parse_dataset(lines)\n",
    "\n",
    "all_sentences = []\n",
    "all_tags = []\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    sentences, annotations = parse_paragraph(paragraph)\n",
    "    tagged_sentences = tag_annotations(sentences, annotations)\n",
    "    for sentence, tags in tagged_sentences:\n",
    "        all_sentences.append(sentence)\n",
    "        all_tags.append(tags)\n",
    "\n",
    "# Parsing the validation dataset file\n",
    "dev_lines = read_dataset(dev_file)\n",
    "dev_paragraphs = parse_dataset(dev_lines)\n",
    "\n",
    "dev_all_sentences = []\n",
    "dev_all_tags = []\n",
    "\n",
    "for dev_paragraph in dev_paragraphs:\n",
    "    dev_sentences, dev_annotations = parse_paragraph(dev_paragraph)\n",
    "    dev_tagged_sentences = tag_annotations(dev_sentences, dev_annotations)\n",
    "    for dev_sentence, dev_tags in dev_tagged_sentences:\n",
    "        dev_all_sentences.append(dev_sentence)\n",
    "        dev_all_tags.append(dev_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset class\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sentences, tags, tokenizer, tag_encoder):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tag_encoder = tag_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        tags = self.tags[idx]\n",
    "\n",
    "        encoding = self.tokenizer(sentence, is_split_into_words=True, return_offsets_mapping=True, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        labels = [-100] * len(encoding['input_ids'][0])\n",
    "\n",
    "        word_ids = encoding.word_ids()\n",
    "        for i, word_idx in enumerate(word_ids):\n",
    "            if word_idx is None:\n",
    "                labels[i] = -100\n",
    "            else:\n",
    "                labels[i] = self.tag_encoder.transform([tags[word_idx]])[0]\n",
    "\n",
    "        return encoding['input_ids'].squeeze(), encoding['attention_mask'].squeeze(), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data\n",
    "all_tags_flat = [tag for tags in all_tags for tag in tags]\n",
    "\n",
    "tag_encoder = LabelEncoder()\n",
    "tag_encoder.fit(all_tags_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adadptive Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "classes = tag_encoder.classes_\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=all_tags_flat)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "dataset = NERDataset(all_sentences, all_tags, tokenizer, tag_encoder)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model and it's characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BERT-based NER Model with weighted loss\n",
    "class BertNERModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, class_weights):\n",
    "        super(BertNERModel, self).__init__()\n",
    "        self.bert = BertForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "        self.dropout = nn.Dropout(0.3)  # Add dropout layer\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = self.dropout(output.logits)  # Apply dropout\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights, ignore_index=-100)\n",
    "            loss = loss_fct(logits.view(-1, self.bert.config.num_labels), labels.view(-1))\n",
    "            return loss, logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Adit\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# Defining the model characteristics\n",
    "model = BertNERModel('bert-base-uncased', len(tag_encoder.classes_), class_weights).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adit\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 21\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     22\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m     23\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\Adit\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Adit\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Adit\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# Training using PyTorch, AdamW Optimizer, CrossEntropyLoss function and \"CUDA\"\n",
    "model.train()\n",
    "loss_dic = {}\n",
    "loss_dic_comp = {}\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_valid_loss = 0\n",
    "\n",
    "    print(f\"Starting Epoch {epoch + 1}\")\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, outputs = model(input_ids, attention_mask, labels)\n",
    "        # loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        print(f\"Batch ID: {batch_idx}, Loss: {loss.item()}\")\n",
    "        loss_dic[batch_idx] = loss.item()\n",
    "\n",
    "    loss_dic_comp[epoch] = loss_dic\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    scheduler.step(avg_loss)  # Adjust learning rate based on average loss\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_plot(title, loss_dic, x_label, y_label, linestyle = '-'):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    x = []\n",
    "    y = []\n",
    "    epo = []\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    for ep, ba_info in loss_dic.items():\n",
    "        epo.append(ep)\n",
    "        for ba_id in ba_info:\n",
    "            y.append(ba_id.values())\n",
    "            x.append(ba_id.keys())\n",
    "            x_data.extend(x)\n",
    "            y_data.extend(y)\n",
    "        x, y = [], []\n",
    "\n",
    "    print (x_data)\n",
    "    print (y_data)\n",
    "    for epoch in epo:\n",
    "        plt.plot(x_data, y_data, linestyle)\n",
    "        plt.legend()\n",
    "    plt.savefig(\"../../Graphs/BERT_CRF_Training.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_plot(\"Batches vs Training Loss\", loss_dic, \"Batches\", \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
