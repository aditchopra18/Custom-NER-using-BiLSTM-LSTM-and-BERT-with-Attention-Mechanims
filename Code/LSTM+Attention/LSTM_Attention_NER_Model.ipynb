{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Relevant Libraries\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing the relevant files\n",
    "train_file = '../../Data/NCBItrainset_corpus.txt'\n",
    "dev_file = '../../Data/NCBIdevelopset_corpus.txt'\n",
    "model_name = '../../Models/LSTM_Attention_NER_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset file\n",
    "def read_dataset(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    return lines\n",
    "\n",
    "def parse_dataset(lines):\n",
    "    paragraphs = []\n",
    "    paragraph = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            paragraph.append(line)\n",
    "        else:\n",
    "            if paragraph:\n",
    "                paragraphs.append(paragraph)\n",
    "                paragraph = []\n",
    "\n",
    "    if paragraph:\n",
    "        paragraphs.append(paragraph)\n",
    "\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the different paragraphs and annotations\n",
    "def parse_paragraph(paragraph):\n",
    "    sentences = []\n",
    "    annotations = []\n",
    "    sentence = []\n",
    "\n",
    "    for line in paragraph:\n",
    "        if re.match(r'^\\d+\\|\\w\\|', line):\n",
    "            sentence.extend(line.split('|')[2].split())\n",
    "\n",
    "        elif re.match(r'^\\d+\\t\\d+\\t\\d+\\t', line):\n",
    "            start, end = int(line.split(\"\\t\")[1]), int(line.split(\"\\t\")[2])\n",
    "            annotations.append((start, end, line.split(\"\\t\")[3], line.split(\"\\t\")[4]))\n",
    "\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "    return sentences, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Labelling\n",
    "def tag_annotations(sentences, annotations):\n",
    "    tagged_sentences = []\n",
    "    char_count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tags = ['O'] * len(sentence)    # Initialize all tags at \"O\"\n",
    "        word_starts = []\n",
    "        word_ends = []\n",
    "        char_pos = 0\n",
    "\n",
    "        for word in sentence:\n",
    "            word_starts.append(char_pos)\n",
    "            char_pos += len(word)\n",
    "            word_ends.append(char_pos)\n",
    "            char_pos += 1               # WhiteSpace Character\n",
    "\n",
    "        '''\n",
    "        Based on the character limits, the annotations are assigned\n",
    "        A custom IO tagging scheme is used\n",
    "        Labels are assigned on the basis of disease label in annotations\n",
    "        '''\n",
    "\n",
    "        for start, end, disease_info, label in annotations:\n",
    "            for i, (word_start, word_end) in enumerate(zip(word_starts, word_ends)):\n",
    "                if word_start >= start and word_end <= end:\n",
    "                    tags[i] = 'I-' + label\n",
    "                elif word_start < start < word_end or word_start < end < word_end:\n",
    "                    tags[i] = 'I-' + label\n",
    "\n",
    "        tagged_sentences.append((sentence, tags))\n",
    "\n",
    "    return tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the dataset file\n",
    "lines = read_dataset(train_file)\n",
    "paragraphs = parse_dataset(lines)\n",
    "\n",
    "all_sentences = []\n",
    "all_tags = []\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    sentences, annotations = parse_paragraph(paragraph)\n",
    "    tagged_sentences = tag_annotations(sentences, annotations)\n",
    "    for sentence, tags in tagged_sentences:\n",
    "        all_sentences.append(sentence)\n",
    "        all_tags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the development dataset file\n",
    "dev_lines = read_dataset(dev_file)\n",
    "dev_paragraphs = parse_dataset(dev_lines)\n",
    "\n",
    "dev_sentences = []\n",
    "dev_tags = []\n",
    "\n",
    "for paragraph in dev_paragraphs:\n",
    "    sentences, annotations = parse_paragraph(paragraph)\n",
    "    tagged_sentences = tag_annotations(sentences, annotations)\n",
    "    for sentence, tags in tagged_sentences:\n",
    "        dev_sentences.append(sentence)\n",
    "        dev_tags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset class\n",
    "class LSTM_Attention_NERDataset(Dataset):\n",
    "    def __init__(self, sentences, tags, word_encoder, tag_encoder, unknown_token='<UNK>'):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "        self.word_encoder = word_encoder\n",
    "        self.tag_encoder = tag_encoder\n",
    "        self.unknown_token = unknown_token\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        tags = self.tags[idx]\n",
    "\n",
    "        sentence_encoded = [self.word_encoder.get(word, self.word_encoder[self.unknown_token]) for word in sentence]\n",
    "        tags_encoded = self.tag_encoder.transform(tags)\n",
    "\n",
    "        return torch.tensor(sentence_encoded), torch.tensor(tags_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "all_words = [word for sentence in all_sentences for word in sentence]\n",
    "all_tags_flat = [tag for tags in all_tags for tag in tags]\n",
    "\n",
    "word_encoder = {word: idx for idx, word in enumerate(set(all_words))}\n",
    "unknown_token = '<UNK>' \n",
    "word_encoder[unknown_token] = len(word_encoder)  # Add unknown token\n",
    "# Done to prevent KeyError as some words might be out of vocabulary in testing dataset\n",
    "\n",
    "tag_encoder = LabelEncoder()\n",
    "tag_encoder.fit(all_tags_flat)\n",
    "\n",
    "dataset = LSTM_Attention_NERDataset(all_sentences, all_tags, word_encoder, tag_encoder, unknown_token)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Global Attention class\n",
    "class Attention (nn.Module):\n",
    "    def __init__ (self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, lstm_output):\n",
    "        # Softmax converts it into a Probability distribution so that the weights are between 0 and 1\n",
    "        attention_weights = torch.softmax(self.attention(lstm_output), dim=1)\n",
    "        weighted_output = lstm_output * attention_weights  # (batch_size, seq_len, hidden_dim)\n",
    "        return weighted_output # (batch_size, hidden_dim)\n",
    "\n",
    "class Attention_LSTM_NER_Model(nn.Module):\n",
    "    def __init__ (self, vocab_size, tagset_size, embedding_dim = 128, hidden_dim = 128):\n",
    "        super(Attention_LSTM_NER_Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first = True)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "\n",
    "    def forward(self, i):\n",
    "        emb = self.embedding(i)\n",
    "        lstm_out , _ = self.lstm(emb)\n",
    "        att_out = self.attention(lstm_out)\n",
    "        tag_space = self.fc(att_out)\n",
    "        return tag_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Defining the model characteristics\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = Attention_LSTM_NER_Model(len(word_encoder), len(tag_encoder.classes_)).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting (to be used to visualize the training loss and validation loss)\n",
    "# Used to figure if the mdoel is underfitting or overfitting\n",
    "def graph_plot(title, x_label, y_label, x_data, y_data, color = 'blue', linestyle = '-'):\n",
    "    plt.plot(x_data, y_data, color = color, linestyle = linestyle)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.savefig(\"../../Graphs/LSTM_Attention_Training.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg_Loss: 1.1892124524242\n",
      "Epoch 2, Avg_Loss: 0.6926511667276684\n",
      "Epoch 3, Avg_Loss: 0.47206690515342514\n",
      "Epoch 4, Avg_Loss: 0.382513500357929\n",
      "Epoch 5, Avg_Loss: 0.34032548258179113\n",
      "Epoch 6, Avg_Loss: 0.3105362669417733\n",
      "Epoch 7, Avg_Loss: 0.2937886267900467\n",
      "Epoch 8, Avg_Loss: 0.289527033112551\n",
      "Epoch 9, Avg_Loss: 0.27416403042642695\n",
      "Epoch 10, Avg_Loss: 0.2640214385954957\n",
      "Epoch 11, Avg_Loss: 0.2587218578708799\n",
      "Epoch 12, Avg_Loss: 0.2543933242559433\n",
      "Epoch 13, Avg_Loss: 0.2512037965812181\n",
      "Epoch 14, Avg_Loss: 0.24616367644385287\n",
      "Epoch 15, Avg_Loss: 0.2365516443785868\n",
      "Epoch 16, Avg_Loss: 0.23399361693545392\n",
      "Epoch 17, Avg_Loss: 0.22682879629888034\n",
      "Epoch 18, Avg_Loss: 0.2214633932239131\n",
      "Epoch 19, Avg_Loss: 0.21765379921386116\n",
      "Epoch 20, Avg_Loss: 0.21530189169080635\n",
      "Epoch 21, Avg_Loss: 0.21099374168797544\n",
      "Epoch 22, Avg_Loss: 0.20725640732991069\n",
      "Epoch 23, Avg_Loss: 0.20659602315802322\n",
      "Epoch 24, Avg_Loss: 0.2044388098936332\n",
      "Epoch 25, Avg_Loss: 0.19850039737004982\n",
      "Epoch 26, Avg_Loss: 0.20058274308317586\n",
      "Epoch 27, Avg_Loss: 0.19535127713492043\n",
      "Epoch 28, Avg_Loss: 0.19803792983293533\n",
      "Epoch 29, Avg_Loss: 0.19487560814932772\n",
      "Epoch 30, Avg_Loss: 0.1867585586089837\n",
      "Epoch 31, Avg_Loss: 0.18625889208755994\n",
      "Epoch 32, Avg_Loss: 0.1826199469597716\n",
      "Epoch 33, Avg_Loss: 0.1804532794968078\n",
      "Epoch 34, Avg_Loss: 0.17642335260384961\n",
      "Epoch 35, Avg_Loss: 0.18283726784743762\n",
      "Epoch 36, Avg_Loss: 0.1745153843964401\n",
      "Epoch 37, Avg_Loss: 0.17790611774513596\n",
      "Epoch 38, Avg_Loss: 0.16909542866051197\n",
      "Epoch 39, Avg_Loss: 0.16809062757774404\n",
      "Epoch 40, Avg_Loss: 0.16612988722657687\n",
      "Epoch 41, Avg_Loss: 0.16989994833343908\n",
      "Epoch 42, Avg_Loss: 0.16758477295699872\n",
      "Epoch 43, Avg_Loss: 0.16692696884274483\n",
      "Epoch 44, Avg_Loss: 0.1647570048900027\n",
      "Epoch 45, Avg_Loss: 0.16323671921303398\n",
      "Epoch 46, Avg_Loss: 0.16560243423047818\n",
      "Epoch 47, Avg_Loss: 0.16195129171798103\n",
      "Epoch 48, Avg_Loss: 0.15754306963399836\n",
      "Epoch 49, Avg_Loss: 0.15801306931596054\n",
      "Epoch 50, Avg_Loss: 0.1628360942398247\n",
      "Epoch 51, Avg_Loss: 0.15645021827597366\n",
      "Epoch 52, Avg_Loss: 0.15694107977967514\n",
      "Epoch 53, Avg_Loss: 0.15951780131772944\n",
      "Epoch 54, Avg_Loss: 0.15170711386752755\n",
      "Epoch 55, Avg_Loss: 0.15194707559911827\n",
      "Epoch 56, Avg_Loss: 0.15121311380674965\n",
      "Epoch 57, Avg_Loss: 0.15330185780399724\n",
      "Epoch 58, Avg_Loss: 0.15274287838684886\n",
      "Epoch 59, Avg_Loss: 0.1479410197781889\n",
      "Epoch 60, Avg_Loss: 0.14515667879267743\n",
      "Epoch 61, Avg_Loss: 0.145326103819044\n",
      "Epoch 62, Avg_Loss: 0.14537098827330688\n",
      "Epoch 63, Avg_Loss: 0.1424606532642716\n",
      "Epoch 64, Avg_Loss: 0.14087008812317722\n",
      "Epoch 65, Avg_Loss: 0.14698302294862897\n",
      "Epoch 66, Avg_Loss: 0.1469176652792253\n",
      "Epoch 67, Avg_Loss: 0.14329305310782633\n",
      "Epoch 68, Avg_Loss: 0.14233813376018875\n",
      "Epoch 69, Avg_Loss: 0.13978520231811623\n",
      "Epoch 70, Avg_Loss: 0.14188908746368006\n",
      "Epoch 71, Avg_Loss: 0.13717888207419923\n",
      "Epoch 72, Avg_Loss: 0.1406738169883427\n",
      "Epoch 73, Avg_Loss: 0.1354741591371988\n",
      "Epoch 74, Avg_Loss: 0.13481390897772813\n",
      "Epoch 75, Avg_Loss: 0.1356912114118275\n",
      "Epoch 76, Avg_Loss: 0.136417970453438\n",
      "Epoch 77, Avg_Loss: 0.13930324621890722\n",
      "Epoch 78, Avg_Loss: 0.13903175176758514\n",
      "Epoch 79, Avg_Loss: 0.13605303572196709\n",
      "Epoch 80, Avg_Loss: 0.13610874253668284\n",
      "Epoch 81, Avg_Loss: 0.1365080064064578\n",
      "Epoch 82, Avg_Loss: 0.13178207999781558\n",
      "Epoch 83, Avg_Loss: 0.13135669145144915\n",
      "Epoch 84, Avg_Loss: 0.13801906061799904\n",
      "Epoch 85, Avg_Loss: 0.13200477765578972\n",
      "Epoch 86, Avg_Loss: 0.13549844195183955\n",
      "Epoch 87, Avg_Loss: 0.13208403379509323\n",
      "Epoch 88, Avg_Loss: 0.1284828556603507\n",
      "Epoch 89, Avg_Loss: 0.12986602830259422\n",
      "Epoch 90, Avg_Loss: 0.1290164533022203\n",
      "Epoch 91, Avg_Loss: 0.13812189647241643\n",
      "Epoch 92, Avg_Loss: 0.1268919622035403\n",
      "Epoch 93, Avg_Loss: 0.12813948408553474\n",
      "Epoch 94, Avg_Loss: 0.12594446804570525\n",
      "Epoch 95, Avg_Loss: 0.12308301085508183\n",
      "Epoch 96, Avg_Loss: 0.12346595143409152\n",
      "Epoch 97, Avg_Loss: 0.1245029584357613\n",
      "Epoch 98, Avg_Loss: 0.12472421813168023\n",
      "Epoch 99, Avg_Loss: 0.12542167913756871\n",
      "Epoch 100, Avg_Loss: 0.12169646020782621\n",
      "Epoch 101, Avg_Loss: 0.12283312843034142\n",
      "Epoch 102, Avg_Loss: 0.12339566902894723\n",
      "Epoch 103, Avg_Loss: 0.12260995864083893\n",
      "Epoch 104, Avg_Loss: 0.12031836631266694\n",
      "Epoch 105, Avg_Loss: 0.12473986689981661\n",
      "Epoch 106, Avg_Loss: 0.12559001088926666\n",
      "Epoch 107, Avg_Loss: 0.1202882111660744\n",
      "Epoch 108, Avg_Loss: 0.12034458000408976\n",
      "Epoch 109, Avg_Loss: 0.12103459033134736\n",
      "Epoch 110, Avg_Loss: 0.12008291659386534\n",
      "Epoch 111, Avg_Loss: 0.12098481074759834\n",
      "Epoch 112, Avg_Loss: 0.12163488919797696\n",
      "Epoch 113, Avg_Loss: 0.1193473423390012\n",
      "Epoch 114, Avg_Loss: 0.12273470214322994\n",
      "Epoch 115, Avg_Loss: 0.11921743558425653\n",
      "Epoch 116, Avg_Loss: 0.1178249434420937\n",
      "Epoch 117, Avg_Loss: 0.11677995049639751\n",
      "Epoch 118, Avg_Loss: 0.1168820409006194\n",
      "Epoch 119, Avg_Loss: 0.11645958396164995\n",
      "Epoch 120, Avg_Loss: 0.11812030524015427\n",
      "Epoch 121, Avg_Loss: 0.11851781390999493\n",
      "Epoch 122, Avg_Loss: 0.11723959759662025\n",
      "Epoch 123, Avg_Loss: 0.1154685445914143\n",
      "Epoch 124, Avg_Loss: 0.11868166864702576\n",
      "Epoch 125, Avg_Loss: 0.11494340840727091\n",
      "Epoch 126, Avg_Loss: 0.11647009026063115\n",
      "Epoch 127, Avg_Loss: 0.11764112605076087\n",
      "Epoch 128, Avg_Loss: 0.11677237781450937\n",
      "Epoch 129, Avg_Loss: 0.11820896754139348\n",
      "Epoch 130, Avg_Loss: 0.11499741791110289\n",
      "Epoch 131, Avg_Loss: 0.11490987123627412\n",
      "Epoch 132, Avg_Loss: 0.11777275937952493\n",
      "Epoch 133, Avg_Loss: 0.11324227307187884\n",
      "Epoch 134, Avg_Loss: 0.11601558759024269\n",
      "Epoch 135, Avg_Loss: 0.11399482288642933\n",
      "Epoch 136, Avg_Loss: 0.11401479475592312\n",
      "Epoch 137, Avg_Loss: 0.11268954939748112\n",
      "Epoch 138, Avg_Loss: 0.11437211871931427\n",
      "Epoch 139, Avg_Loss: 0.1128018306274163\n",
      "Epoch 140, Avg_Loss: 0.11346460565140373\n",
      "Epoch 141, Avg_Loss: 0.11094971922667403\n",
      "Epoch 142, Avg_Loss: 0.11748564831520382\n",
      "Epoch 143, Avg_Loss: 0.12197707632654592\n",
      "Epoch 144, Avg_Loss: 0.11626029073407776\n",
      "Epoch 145, Avg_Loss: 0.1249232798030502\n",
      "Epoch 146, Avg_Loss: 0.11924478843023903\n",
      "Epoch 147, Avg_Loss: 0.11282058040562429\n",
      "Epoch 148, Avg_Loss: 0.11415724554344227\n",
      "Epoch 149, Avg_Loss: 0.11106234450677507\n",
      "Epoch 150, Avg_Loss: 0.11227001073329072\n",
      "Epoch 151, Avg_Loss: 0.10996066367155627\n",
      "Epoch 152, Avg_Loss: 0.11027178462398679\n",
      "Epoch 153, Avg_Loss: 0.10902680574279082\n",
      "Epoch 154, Avg_Loss: 0.10929220522704877\n",
      "Epoch 155, Avg_Loss: 0.10792885073705723\n",
      "Epoch 156, Avg_Loss: 0.10790870730814181\n",
      "Epoch 157, Avg_Loss: 0.10757951458033763\n",
      "Epoch 158, Avg_Loss: 0.1093367075449542\n",
      "Epoch 159, Avg_Loss: 0.11022189445793629\n",
      "Epoch 160, Avg_Loss: 0.10747506155779488\n",
      "Epoch 161, Avg_Loss: 0.1063470957604678\n",
      "Epoch 162, Avg_Loss: 0.11193825108440299\n",
      "Epoch 163, Avg_Loss: 0.1071751327498963\n",
      "Epoch 164, Avg_Loss: 0.10963547719936621\n",
      "Epoch 165, Avg_Loss: 0.10663603579527453\n",
      "Epoch 166, Avg_Loss: 0.10563777465569346\n",
      "Epoch 167, Avg_Loss: 0.10864566364570667\n",
      "Epoch 168, Avg_Loss: 0.10483027945615743\n",
      "Epoch 169, Avg_Loss: 0.10645566684635062\n",
      "Epoch 170, Avg_Loss: 0.10622796367265676\n",
      "Epoch 171, Avg_Loss: 0.10579699964115494\n",
      "Epoch 172, Avg_Loss: 0.10535774870138419\n",
      "Epoch 173, Avg_Loss: 0.10361471693766744\n",
      "Epoch 174, Avg_Loss: 0.10863763839006424\n",
      "Epoch 175, Avg_Loss: 0.10481646990305499\n",
      "Epoch 176, Avg_Loss: 0.10885150926677804\n",
      "Epoch 177, Avg_Loss: 0.10754211246967316\n",
      "Epoch 178, Avg_Loss: 0.11102429169573282\n",
      "Epoch 179, Avg_Loss: 0.1085387971252203\n",
      "Epoch 180, Avg_Loss: 0.10659306849303998\n",
      "Epoch 181, Avg_Loss: 0.10730880126357079\n",
      "Epoch 182, Avg_Loss: 0.10269367449769848\n",
      "Epoch 183, Avg_Loss: 0.10406265094092018\n",
      "Epoch 184, Avg_Loss: 0.10304095909783714\n",
      "Epoch 185, Avg_Loss: 0.10344227109300463\n",
      "Epoch 186, Avg_Loss: 0.10055410940396159\n",
      "Epoch 187, Avg_Loss: 0.10340894072463638\n",
      "Epoch 188, Avg_Loss: 0.10008020620597036\n",
      "Epoch 189, Avg_Loss: 0.09810153247886583\n",
      "Epoch 190, Avg_Loss: 0.09798968171602801\n",
      "Epoch 191, Avg_Loss: 0.09699913741726625\n",
      "Epoch 192, Avg_Loss: 0.0990984694738137\n",
      "Epoch 193, Avg_Loss: 0.09623517723459947\n",
      "Epoch 194, Avg_Loss: 0.09617587394620243\n",
      "Epoch 195, Avg_Loss: 0.0986109577903622\n",
      "Epoch 196, Avg_Loss: 0.09554356787549823\n",
      "Epoch 197, Avg_Loss: 0.0973684991660871\n",
      "Epoch 198, Avg_Loss: 0.09358646490268017\n",
      "Epoch 199, Avg_Loss: 0.09712447971105576\n",
      "Epoch 200, Avg_Loss: 0.09576723959885146\n",
      "Epoch 201, Avg_Loss: 0.092421554886785\n",
      "Epoch 202, Avg_Loss: 0.09714199926115964\n",
      "Epoch 203, Avg_Loss: 0.09773267825183116\n",
      "Epoch 204, Avg_Loss: 0.09409239447038424\n",
      "Epoch 205, Avg_Loss: 0.10247306349246126\n",
      "Epoch 206, Avg_Loss: 0.10020819737723\n",
      "Epoch 207, Avg_Loss: 0.0968182509470927\n",
      "Epoch 208, Avg_Loss: 0.09609308172213404\n",
      "Epoch 209, Avg_Loss: 0.0946626047554769\n",
      "Epoch 210, Avg_Loss: 0.0929535529331157\n",
      "Epoch 211, Avg_Loss: 0.09382479412383155\n",
      "Epoch 212, Avg_Loss: 0.09086048946176704\n",
      "Epoch 213, Avg_Loss: 0.09114155124284719\n",
      "Epoch 214, Avg_Loss: 0.09137294108146116\n",
      "Epoch 215, Avg_Loss: 0.08959821101866271\n",
      "Epoch 216, Avg_Loss: 0.09370991901347511\n",
      "Epoch 217, Avg_Loss: 0.08709479917428996\n",
      "Epoch 218, Avg_Loss: 0.08812499134556244\n",
      "Epoch 219, Avg_Loss: 0.08589750371481243\n",
      "Epoch 220, Avg_Loss: 0.0859621319135553\n",
      "Epoch 221, Avg_Loss: 0.08714921782283407\n",
      "Epoch 222, Avg_Loss: 0.08290206091968637\n",
      "Epoch 223, Avg_Loss: 0.08281821473256538\n",
      "Epoch 224, Avg_Loss: 0.08326006719940587\n",
      "Epoch 225, Avg_Loss: 0.08368032582496342\n",
      "Epoch 226, Avg_Loss: 0.09407968985799112\n",
      "Epoch 227, Avg_Loss: 0.08789040991350223\n",
      "Epoch 228, Avg_Loss: 0.08374808013047043\n",
      "Epoch 229, Avg_Loss: 0.08471498177631905\n",
      "Epoch 230, Avg_Loss: 0.07954437416782112\n",
      "Epoch 231, Avg_Loss: 0.08013051552207846\n",
      "Epoch 232, Avg_Loss: 0.07792276795953512\n",
      "Epoch 233, Avg_Loss: 0.08199621638969372\n",
      "Epoch 234, Avg_Loss: 0.07670070473594885\n",
      "Epoch 235, Avg_Loss: 0.07804507066152598\n",
      "Epoch 236, Avg_Loss: 0.07646549649928745\n",
      "Epoch 237, Avg_Loss: 0.07662303324200605\n",
      "Epoch 238, Avg_Loss: 0.07791441894675556\n",
      "Epoch 239, Avg_Loss: 0.07743749904789422\n",
      "Epoch 240, Avg_Loss: 0.0750827589317372\n",
      "Epoch 241, Avg_Loss: 0.07884566691753112\n",
      "Epoch 242, Avg_Loss: 0.07665767010889556\n",
      "Epoch 243, Avg_Loss: 0.0751549797622781\n",
      "Epoch 244, Avg_Loss: 0.07360282432484\n",
      "Epoch 245, Avg_Loss: 0.07281020881706163\n",
      "Epoch 246, Avg_Loss: 0.07444073240223684\n",
      "Epoch 247, Avg_Loss: 0.07422193933866526\n",
      "Epoch 248, Avg_Loss: 0.07353713255571692\n",
      "Epoch 249, Avg_Loss: 0.07179436901290166\n",
      "Epoch 250, Avg_Loss: 0.0702024573999408\n",
      "Epoch 251, Avg_Loss: 0.07113769552425335\n",
      "Epoch 252, Avg_Loss: 0.0712968176720958\n",
      "Epoch 253, Avg_Loss: 0.07591225491150429\n",
      "Epoch 254, Avg_Loss: 0.07107847250115715\n",
      "Epoch 255, Avg_Loss: 0.07132699311171707\n",
      "Epoch 256, Avg_Loss: 0.0701859912001773\n",
      "Epoch 257, Avg_Loss: 0.06884934699260875\n",
      "Epoch 258, Avg_Loss: 0.0686397336815533\n",
      "Epoch 259, Avg_Loss: 0.06926939734502842\n",
      "Epoch 260, Avg_Loss: 0.06972998959061347\n",
      "Epoch 261, Avg_Loss: 0.06744446438786231\n",
      "Epoch 262, Avg_Loss: 0.06805317586679992\n",
      "Epoch 263, Avg_Loss: 0.06972458184157547\n",
      "Epoch 264, Avg_Loss: 0.07213236469971507\n",
      "Epoch 265, Avg_Loss: 0.07093396361329053\n",
      "Epoch 266, Avg_Loss: 0.07068734596434392\n",
      "Epoch 267, Avg_Loss: 0.06926052880130316\n",
      "Epoch 268, Avg_Loss: 0.06797196363147937\n",
      "Epoch 269, Avg_Loss: 0.06655960608469813\n",
      "Epoch 270, Avg_Loss: 0.06553534447754684\n",
      "Epoch 271, Avg_Loss: 0.06348072016905797\n",
      "Epoch 272, Avg_Loss: 0.06301413804880883\n",
      "Epoch 273, Avg_Loss: 0.061889917834808954\n",
      "Epoch 274, Avg_Loss: 0.06306077961466815\n",
      "Epoch 275, Avg_Loss: 0.06406431154985177\n",
      "Epoch 276, Avg_Loss: 0.0619293182205997\n",
      "Epoch 277, Avg_Loss: 0.06173092739558533\n",
      "Epoch 278, Avg_Loss: 0.061955744498654416\n",
      "Epoch 279, Avg_Loss: 0.06198534085170219\n",
      "Epoch 280, Avg_Loss: 0.06419602722713821\n",
      "Epoch 281, Avg_Loss: 0.0596584752202034\n",
      "Epoch 282, Avg_Loss: 0.058791756678960826\n",
      "Epoch 283, Avg_Loss: 0.0601464532511799\n",
      "Epoch 284, Avg_Loss: 0.06102211489097068\n",
      "Epoch 285, Avg_Loss: 0.05977239941957554\n",
      "Epoch 286, Avg_Loss: 0.05861872566961929\n",
      "Epoch 287, Avg_Loss: 0.05916727451901687\n",
      "Epoch 288, Avg_Loss: 0.06227389850506657\n",
      "Epoch 289, Avg_Loss: 0.05826043009169792\n",
      "Epoch 290, Avg_Loss: 0.06044370818294977\n",
      "Epoch 291, Avg_Loss: 0.058728521322145275\n",
      "Epoch 292, Avg_Loss: 0.05738476212871702\n",
      "Epoch 293, Avg_Loss: 0.05718751545799406\n",
      "Epoch 294, Avg_Loss: 0.0551001241822776\n",
      "Epoch 295, Avg_Loss: 0.055079183590255286\n",
      "Epoch 296, Avg_Loss: 0.05754414877217067\n",
      "Epoch 297, Avg_Loss: 0.062396156160455\n",
      "Epoch 298, Avg_Loss: 0.0573361505705275\n",
      "Epoch 299, Avg_Loss: 0.05539058893918991\n",
      "Epoch 300, Avg_Loss: 0.056878581839172465\n",
      "Epoch 301, Avg_Loss: 0.05809298486105705\n",
      "Epoch 302, Avg_Loss: 0.05592265793759572\n",
      "Epoch 303, Avg_Loss: 0.055092757861865196\n",
      "Epoch 304, Avg_Loss: 0.05334187632328585\n",
      "Epoch 305, Avg_Loss: 0.05761634734900374\n",
      "Epoch 306, Avg_Loss: 0.05205089547426293\n",
      "Epoch 307, Avg_Loss: 0.05160062867952021\n",
      "Epoch 308, Avg_Loss: 0.052771335990033356\n",
      "Epoch 309, Avg_Loss: 0.05089780869648645\n",
      "Epoch 310, Avg_Loss: 0.05034683806527602\n",
      "Epoch 311, Avg_Loss: 0.04940068533055877\n",
      "Epoch 312, Avg_Loss: 0.04930448242904324\n",
      "Epoch 313, Avg_Loss: 0.04968501397065426\n",
      "Epoch 314, Avg_Loss: 0.0491710248844404\n",
      "Epoch 315, Avg_Loss: 0.04898883426856054\n",
      "Epoch 316, Avg_Loss: 0.05401822522674736\n",
      "Epoch 317, Avg_Loss: 0.05196673364231461\n",
      "Epoch 318, Avg_Loss: 0.054190811995220814\n",
      "Epoch 319, Avg_Loss: 0.05221432849372688\n",
      "Epoch 320, Avg_Loss: 0.05349615368207818\n",
      "Epoch 321, Avg_Loss: 0.05130218253716042\n",
      "Epoch 322, Avg_Loss: 0.056566974246188215\n",
      "Epoch 323, Avg_Loss: 0.06498858188033889\n",
      "Epoch 324, Avg_Loss: 0.061559864491420355\n",
      "Epoch 325, Avg_Loss: 0.059605685405825316\n",
      "Epoch 326, Avg_Loss: 0.053647263906896114\n",
      "Epoch 327, Avg_Loss: 0.05123332510457227\n",
      "Epoch 328, Avg_Loss: 0.058646465798741894\n",
      "Epoch 329, Avg_Loss: 0.0560421783379034\n",
      "Epoch 330, Avg_Loss: 0.04979561089145902\n",
      "Epoch 331, Avg_Loss: 0.04813172633906728\n",
      "Epoch 332, Avg_Loss: 0.04849703448187364\n",
      "Epoch 333, Avg_Loss: 0.048772247606202176\n",
      "Epoch 334, Avg_Loss: 0.05130145752704457\n",
      "Epoch 335, Avg_Loss: 0.045204736782531986\n",
      "Epoch 336, Avg_Loss: 0.04473935915647369\n",
      "Epoch 337, Avg_Loss: 0.04512202352481453\n",
      "Epoch 338, Avg_Loss: 0.04405105628661419\n",
      "Epoch 339, Avg_Loss: 0.045311137739765014\n",
      "Epoch 340, Avg_Loss: 0.043719260512213955\n",
      "Epoch 341, Avg_Loss: 0.045930023746270886\n",
      "Epoch 342, Avg_Loss: 0.04459415062477714\n",
      "Epoch 343, Avg_Loss: 0.042423205156075325\n",
      "Epoch 344, Avg_Loss: 0.0433404363299671\n",
      "Epoch 345, Avg_Loss: 0.041151487639198375\n",
      "Epoch 346, Avg_Loss: 0.040947741448977275\n",
      "Epoch 347, Avg_Loss: 0.040283733341646824\n",
      "Epoch 348, Avg_Loss: 0.03933559738001541\n",
      "Epoch 349, Avg_Loss: 0.04223590050088732\n",
      "Epoch 350, Avg_Loss: 0.04936412466984046\n",
      "Epoch 351, Avg_Loss: 0.047275211367952194\n",
      "Epoch 352, Avg_Loss: 0.04334853660609377\n",
      "Epoch 353, Avg_Loss: 0.04366845426786887\n",
      "Epoch 354, Avg_Loss: 0.04334183208840458\n",
      "Epoch 355, Avg_Loss: 0.04111698843342693\n",
      "Epoch 356, Avg_Loss: 0.042714889455390606\n",
      "Epoch 357, Avg_Loss: 0.03965883234846651\n",
      "Epoch 358, Avg_Loss: 0.038475638402527886\n",
      "Epoch 359, Avg_Loss: 0.037770135548750035\n",
      "Epoch 360, Avg_Loss: 0.03876054502631489\n",
      "Epoch 361, Avg_Loss: 0.038087474721434866\n",
      "Epoch 362, Avg_Loss: 0.037451380398124456\n",
      "Epoch 363, Avg_Loss: 0.03798785139071314\n",
      "Epoch 364, Avg_Loss: 0.04102689625793382\n",
      "Epoch 365, Avg_Loss: 0.03690174746474153\n",
      "Epoch 366, Avg_Loss: 0.036729479306622556\n",
      "Epoch 367, Avg_Loss: 0.03737192998003019\n",
      "Epoch 368, Avg_Loss: 0.03631013320562871\n",
      "Epoch 369, Avg_Loss: 0.03547260349028205\n",
      "Epoch 370, Avg_Loss: 0.035773701279571184\n",
      "Epoch 371, Avg_Loss: 0.034593952917738965\n",
      "Epoch 372, Avg_Loss: 0.03528597022063638\n",
      "Epoch 373, Avg_Loss: 0.034534329848707114\n",
      "Epoch 374, Avg_Loss: 0.03365297887572333\n",
      "Epoch 375, Avg_Loss: 0.03479902627632806\n",
      "Epoch 376, Avg_Loss: 0.03848784500242848\n",
      "Epoch 377, Avg_Loss: 0.03992107500763316\n",
      "Epoch 378, Avg_Loss: 0.04060878281138445\n",
      "Epoch 379, Avg_Loss: 0.0450835139643842\n",
      "Epoch 380, Avg_Loss: 0.048645074185180034\n",
      "Epoch 381, Avg_Loss: 0.04160337865744766\n",
      "Epoch 382, Avg_Loss: 0.04124080958335023\n",
      "Epoch 383, Avg_Loss: 0.041127269303328114\n",
      "Epoch 384, Avg_Loss: 0.047026005426519794\n",
      "Epoch 385, Avg_Loss: 0.04297504314270459\n",
      "Epoch 386, Avg_Loss: 0.039232296869158745\n",
      "Epoch 387, Avg_Loss: 0.03973388093474664\n",
      "Epoch 388, Avg_Loss: 0.03743654869398788\n",
      "Epoch 389, Avg_Loss: 0.03548466997515214\n",
      "Epoch 390, Avg_Loss: 0.03382976510022816\n",
      "Epoch 391, Avg_Loss: 0.033131047813711983\n",
      "Epoch 392, Avg_Loss: 0.0347743815938501\n",
      "Epoch 393, Avg_Loss: 0.03193071104684159\n",
      "Epoch 394, Avg_Loss: 0.03139354376808593\n",
      "Epoch 395, Avg_Loss: 0.031098943350738602\n",
      "Epoch 396, Avg_Loss: 0.030620610905124954\n",
      "Epoch 397, Avg_Loss: 0.03021079623508022\n",
      "Epoch 398, Avg_Loss: 0.02959261042997241\n",
      "Epoch 399, Avg_Loss: 0.029658233918445676\n",
      "Epoch 400, Avg_Loss: 0.029271702992876892\n",
      "Epoch 401, Avg_Loss: 0.028598992729951676\n",
      "Epoch 402, Avg_Loss: 0.02928967896456781\n",
      "Epoch 403, Avg_Loss: 0.03295546498051599\n",
      "Epoch 404, Avg_Loss: 0.03490290860798651\n",
      "Epoch 405, Avg_Loss: 0.03376485512126237\n",
      "Epoch 406, Avg_Loss: 0.0331574140949861\n",
      "Epoch 407, Avg_Loss: 0.03438763963181133\n",
      "Epoch 408, Avg_Loss: 0.039525434619894155\n",
      "Epoch 409, Avg_Loss: 0.03632001304312756\n",
      "Epoch 410, Avg_Loss: 0.034234354615603625\n",
      "Epoch 411, Avg_Loss: 0.03994032007789141\n",
      "Epoch 412, Avg_Loss: 0.036672038761408704\n",
      "Epoch 413, Avg_Loss: 0.0327704578245941\n",
      "Epoch 414, Avg_Loss: 0.03421925317103926\n",
      "Epoch 415, Avg_Loss: 0.03206711362949327\n",
      "Epoch 416, Avg_Loss: 0.030385075186036135\n",
      "Epoch 417, Avg_Loss: 0.029299479198495026\n",
      "Epoch 418, Avg_Loss: 0.030491380241552467\n",
      "Epoch 419, Avg_Loss: 0.030602774092633473\n",
      "Epoch 420, Avg_Loss: 0.028759952836768014\n"
     ]
    }
   ],
   "source": [
    "# Storing the values of different losses with epochs\n",
    "loss_dic = {}\n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(420):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        sentences, tags = zip(*batch)\n",
    "        sentences = torch.nn.utils.rnn.pad_sequence(sentences, batch_first=True).to(device)\n",
    "        tags = torch.nn.utils.rnn.pad_sequence(tags, batch_first=True, padding_value=-100).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sentences)\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        loss = criterion(outputs, tags)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Avg_Loss: {total_loss / len(dataloader)}\")\n",
    "    loss_dic[epoch + 1] = total_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_plot(\"Training Loss vs Epochs\", \"Epochs\", \"Avg Loss\", list(loss_dic.keys()), list(loss_dic.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model as a .pth file\n",
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "\n",
    "# Load the test dataset\n",
    "test_file = '../../Data/NCBItestset_corpus.txt'\n",
    "test_lines = read_dataset(test_file)\n",
    "test_paragraphs = parse_dataset(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing and storing the test dataset\n",
    "test_sentences = []\n",
    "test_tags = []\n",
    "\n",
    "for paragraph in test_paragraphs:\n",
    "    sentences, annotations = parse_paragraph(paragraph)\n",
    "    tagged_sentences = tag_annotations(sentences, annotations)\n",
    "    for sentence, tags in tagged_sentences:\n",
    "        test_sentences.append(sentence)\n",
    "        test_tags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention_LSTM_NER_Model(\n",
       "  (lstm): LSTM(128, 128, batch_first=True)\n",
       "  (embedding): Embedding(14805, 128)\n",
       "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (attention): Attention(\n",
       "    (attention): Linear(in_features=128, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the model file\n",
    "model = Attention_LSTM_NER_Model(len(word_encoder), len(tag_encoder.classes_)).to(device)\n",
    "model.load_state_dict(torch.load(model_name))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "I-CompositeMention       0.83      0.06      0.11        89\n",
      "    I-DiseaseClass       0.19      0.38      0.25       255\n",
      "        I-Modifier       0.56      0.48      0.52       367\n",
      " I-SpecificDisease       0.56      0.60      0.58      1090\n",
      "                 O       0.97      0.96      0.97     18601\n",
      "\n",
      "          accuracy                           0.93     20402\n",
      "         macro avg       0.62      0.50      0.48     20402\n",
      "      weighted avg       0.93      0.93      0.93     20402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test data\n",
    "test_dataset = LSTM_Attention_NERDataset(test_sentences, test_tags, word_encoder, tag_encoder, '<UNK>')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=lambda x: x)\n",
    "\n",
    "# Evaluate the model\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "result = \"../../Result/TestResults_AttentionLSTM_NER.txt\"\n",
    "with open(result, 'w') as t_file:\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            sentences, tags = zip(*batch)\n",
    "            sentences = torch.nn.utils.rnn.pad_sequence(sentences, batch_first=True).to(device)\n",
    "            tags = torch.nn.utils.rnn.pad_sequence(tags, batch_first=True, padding_value=-100).to(device)\n",
    "\n",
    "            outputs = model(sentences)\n",
    "            outputs = outputs.view(-1, outputs.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            true_labels = tags.cpu().numpy()\n",
    "\n",
    "            mask = true_labels != -100\n",
    "            pred_labels = predictions[mask]\n",
    "            true_labels = true_labels[mask]\n",
    "\n",
    "            pred_labels_decoded = tag_encoder.inverse_transform(pred_labels)\n",
    "            true_labels_decoded = tag_encoder.inverse_transform(true_labels)\n",
    "\n",
    "            for true_label, pred_label in zip(true_labels_decoded, pred_labels_decoded):\n",
    "                t_file.write(f'True: {true_label}, Pred: {pred_label}\\n')\n",
    "                all_true_labels.append(true_label)\n",
    "                all_pred_labels.append(pred_label)\n",
    "\n",
    "# Printing classification report\n",
    "report = classification_report(all_true_labels, all_pred_labels)\n",
    "print (report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
